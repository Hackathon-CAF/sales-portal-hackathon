{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNVXn1xwP6ix"
      },
      "outputs": [],
      "source": [
        "# Instalando depend√™ncias b√°sicas\n",
        "!pip install pandas streamlit requests python-dotenv\n",
        "\n",
        "# Instalando bibliotecas para o LLM Open Source (Usaremos Transformers para carregar um modelo)\n",
        "!pip install transformers accelerate bitsandbytes sentencepiece\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo A: No SEU COMPUTADOR (Onde a API est√° rodando)\n",
        "Instale o ngrok:\n",
        "\n",
        "Baixe o ngrok no site oficial e adicione-o ao PATH ou use-o na pasta onde ele foi baixado.\n",
        "\n",
        "Crie uma conta gratuita no ngrok e obtenha seu Auth Token.\n",
        "\n",
        "Exponha sua API (a porta 3000): Abra seu terminal ou prompt de comando (no seu computador) e execute:\n",
        "\n",
        "ngrok http 3000\n",
        "\n",
        "Anote o URL P√∫blico: O ngrok ir√° gerar um URL p√∫blico tempor√°rio (ex: https://abcd-123-45-678-90.ngrok-free.app). Este √© o seu novo URL_API.\n"
      ],
      "metadata": {
        "id": "QezNy_-hbxCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# --- CONFIGURA√á√ÉO DE ACESSO √Ä API (SUBSTITUA PELOS SEUS VALORES REAIS) ---\n",
        "NGROK_URL = \"SUA_URL_NGROK_AQUI\"\n",
        "URL_API_REAL = f\"{NGROK_URL}/api/transactions/dashboard\"\n",
        "API_DASHBOARD_KEY_VALUE = \"SUA_CHAVE_API_AQUI\"\n",
        "MODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "# --- FUN√á√ïES DE CARREGAMENTO E PROCESSAMENTO DE DADOS ---\n",
        "\n",
        "def map_region(estado):\n",
        "    if not estado: return \"Desconhecida\"\n",
        "    estado = estado.upper()\n",
        "    if estado in [\"AC\", \"AP\", \"AM\", \"PA\", \"RO\", \"RR\", \"TO\"]: return \"Norte\"\n",
        "    elif estado in [\"AL\", \"BA\", \"CE\", \"MA\", \"PB\", \"PE\", \"PI\", \"RN\", \"SE\"]: return \"Nordeste\"\n",
        "    elif estado in [\"DF\", \"GO\", \"MT\", \"MS\"]: return \"Centro-Oeste\"\n",
        "    elif estado in [\"ES\", \"MG\", \"RJ\", \"SP\"]: return \"Sudeste\"\n",
        "    elif estado in [\"PR\", \"RS\", \"SC\"]: return \"Sul\"\n",
        "    else: return \"Desconhecida\"\n",
        "\n",
        "def carregar_dados_api_real():\n",
        "    headers = {\"x-api-key\": API_DASHBOARD_KEY_VALUE}\n",
        "    print(f\"Tentando conectar na API: {URL_API_REAL}\")\n",
        "    try:\n",
        "        response = requests.get(URL_API_REAL, headers=headers, timeout=15)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        df_bruto = pd.DataFrame(response.json().get(\"data\", []))\n",
        "        if df_bruto.empty: return pd.DataFrame()\n",
        "\n",
        "        # Flatten\n",
        "        if 'customer' in df_bruto.columns and 'product' in df_bruto.columns:\n",
        "            df_bruto = pd.concat([\n",
        "                df_bruto.drop(['customer', 'product'], axis=1),\n",
        "                df_bruto['customer'].apply(pd.Series).add_prefix('customer_'),\n",
        "                df_bruto['product'].apply(pd.Series).add_prefix('product_')\n",
        "            ], axis=1)\n",
        "\n",
        "        # Renomear e processar\n",
        "        df_renomeado = df_bruto.rename(columns={\n",
        "            'totalPrice': 'preco_total_item', 'date': 'data_pedido', 'status': 'status_pedido',\n",
        "            'customer_name': 'nome_cliente', 'customer_segment': 'segmento_cliente',\n",
        "            'customer_city': 'cidade', 'customer_state': 'estado',\n",
        "            'product_name': 'nome_produto', 'product_quantity': 'quantidade'\n",
        "        })\n",
        "\n",
        "        df_renomeado['regiao'] = df_renomeado['estado'].apply(map_region)\n",
        "        df_renomeado['data_pedido'] = pd.to_datetime(df_renomeado['data_pedido'])\n",
        "        df_renomeado['mes_ano'] = df_renomeado['data_pedido'].dt.to_period('M').astype(str)\n",
        "        return df_renomeado\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"ERRO DE CONEX√ÉO: {e}. Usando dados simulados como fallback.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# --- FUN√á√ÉO DE FALLBACK PARA DADOS SIMULADOS ---\n",
        "def gerar_dados_simulados():\n",
        "    np.random.seed(42)\n",
        "    num_pedidos = 1000\n",
        "    estados = [\"SP\", \"RJ\", \"MG\", \"BA\", \"PE\", \"RS\", \"PR\", \"AM\", \"GO\"]\n",
        "    pesos_produtos = np.linspace(0.01, 0.1, 20)\n",
        "    probabilidades_produtos = pesos_produtos / np.sum(pesos_produtos)\n",
        "    data = {\n",
        "        'orderId': np.arange(1000, 1000 + num_pedidos), 'preco_total_item': np.round(np.random.uniform(10.0, 500.0, num_pedidos), 2),\n",
        "        'data_pedido': pd.to_datetime(pd.date_range(start='2024-01-01', periods=num_pedidos, freq='D')),\n",
        "        'status_pedido': np.random.choice([\"Completed\", \"Pending\", \"Canceled\", \"Processing\"], num_pedidos, p=[0.75, 0.15, 0.05, 0.05]),\n",
        "        'nome_cliente': [f\"Cliente_{i % 100}\" for i in range(num_pedidos)],\n",
        "        'segmento_cliente': np.random.choice([\"Gold\", \"Silver\", \"Bronze\", \"Standard\"], num_pedidos, p=[0.15, 0.25, 0.35, 0.25]),\n",
        "        'cidade': [f\"Cidade_{i % 50}\" for i in range(num_pedidos)], 'estado': np.random.choice(estados, num_pedidos),\n",
        "        'nome_produto': np.random.choice([f\"Produto_{i}\" for i in range(20)], num_pedidos, p=probabilidades_produtos),\n",
        "        'quantidade': np.random.randint(1, 6, num_pedidos)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df['regiao'] = df['estado'].apply(map_region)\n",
        "    df['mes_ano'] = df['data_pedido'].dt.to_period('M').astype(str)\n",
        "    return df\n",
        "\n",
        "# --- CARREGAMENTO DE DADOS E KPIS ---\n",
        "df = carregar_dados_api_real()\n",
        "\n",
        "if df.empty:\n",
        "    df = gerar_dados_simulados()\n",
        "\n",
        "receita_total = df['preco_total_item'].sum()\n",
        "pedidos_unicos = df['orderId'].nunique()\n",
        "df_kpi = pd.DataFrame([{'receita_total': receita_total, 'pedidos_unicos': pedidos_unicos, 'ticket_medio': receita_total / pedidos_unicos if pedidos_unicos > 0 else 0}])\n",
        "print(f\"‚úÖ An√°lise pronta para {len(df)} registros.\")\n",
        "\n",
        "# --- AGENTE DE IA (CARREGAMENTO DO MODELO) ---\n",
        "try:\n",
        "    global tokenizer, model\n",
        "    _ = tokenizer; _ = model\n",
        "    print(f\"Modelo {MODEL_NAME} j√° carregado. Pulando carregamento.\")\n",
        "except NameError:\n",
        "    print(f\"Carregando Modelo {MODEL_NAME} (Phi-3)...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16, trust_remote_code=True\n",
        "        )\n",
        "        print(f\"Modelo {MODEL_NAME} carregado com sucesso.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERRO FATAL ao carregar o modelo: {e}\")\n",
        "        raise SystemExit(e)\n",
        "\n",
        "# --- FUN√á√ÉO DE INFER√äNCIA ---\n",
        "def generate_insights(prompt):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "    model_inputs = encodeds.to(model.device)\n",
        "\n",
        "    generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True, temperature=0.7, pad_token_id=tokenizer.eos_token_id)\n",
        "    response = tokenizer.decode(generated_ids[0], skip_special_tokens=False)\n",
        "\n",
        "    # Limpeza da resposta do Phi-3\n",
        "    try:\n",
        "        start_index = response.index('[/INST]') + len('[/INST]')\n",
        "        return response[start_index:].strip()\n",
        "    except ValueError:\n",
        "        return response.strip()\n",
        "\n",
        "# --- PREPARA√á√ÉO DOS DADOS E PROMPT ---\n",
        "data_summary = f\"\"\"\n",
        "## Resumo do Dataframe de Vendas:\n",
        "* **Total de Pedidos:** {df_kpi['pedidos_unicos'].iloc[0]}\n",
        "* **Receita Total:** R$ {df_kpi['receita_total'].iloc[0]:,.2f}\n",
        "* **Ticket M√©dio Global:** R$ {df_kpi['ticket_medio'].iloc[0]:,.2f}\n",
        "\n",
        "## Agregados Relevantes:\n",
        "* **Receita por Status:**\n",
        "{df.groupby('status_pedido')['preco_total_item'].sum().sort_values(ascending=False).to_markdown()}\n",
        "* **Receita por Regi√£o (Top 3):**\n",
        "{df.groupby('regiao')['preco_total_item'].sum().nlargest(3).to_markdown()}\n",
        "* **Produtos Mais Vendidos (Top 5 em Receita):**\n",
        "{df.groupby('nome_produto')['preco_total_item'].sum().nlargest(5).to_markdown()}\n",
        "* **Segmento de Cliente (Receita Total):**\n",
        "{df.groupby('segmento_cliente')['preco_total_item'].sum().sort_values(ascending=False).to_markdown()}\n",
        "\"\"\"\n",
        "\n",
        "analyst_prompt = f\"\"\"\n",
        "Voc√™ √© um Analista de Dados S√™nior, fluente em Portugu√™s do Brasil.\n",
        "Sua tarefa √© analisar os dados de vendas fornecidos e produzir uma an√°lise focada em Tomada de Decis√£o.\n",
        "\n",
        "Instru√ß√µes Cruciais:\n",
        "1.  **IDIOMA:** A resposta DEVE ser 100% em Portugu√™s do Brasil.\n",
        "2.  **FORMATO:** Gere 5 insights essenciais, formatados como uma lista numerada.\n",
        "3.  **ESTRUTURA:** Cada ponto deve seguir esta estrutura EXATA, utilizando negrito:\n",
        "    * **Insight Chave:** [O fato principal e a evid√™ncia num√©rica (R$, o s√≠mbolo oficial do Real, a moeda brasileira) extra√≠da dos dados.]\n",
        "    * **Recomenda√ß√£o Acion√°vel:** [O que a equipe de vendas/marketing deve fazer com base no insight.]\n",
        "\n",
        "4.  **REGRAS R√çGIDAS DE FORMATA√á√ÉO:**\n",
        "    * N√ÉO use as palavras 'Analyze', 'Analysis', 'Recommendation' ou 'Recomenda√ß√£o' como cabe√ßalhos.\n",
        "    * Use o formato monet√°rio (R$) corretamente.\n",
        "\n",
        "--- DADOS PARA AN√ÅLISE ---\n",
        "{data_summary}\n",
        "--- FIM DOS DADOS ---\n",
        "\n",
        "## üìä An√°lise de 5 Pontos com A√ß√µes Recomendadas:\n",
        "\"\"\"\n",
        "\n",
        "# --- EXECU√á√ÉO E EXIBI√á√ÉO ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ü§ñ AGENTE DE INSIGHTS DE IA EM EXECU√á√ÉO...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "insights = generate_insights(analyst_prompt)\n",
        "\n",
        "print(\"\\n\" + \"#\"*50)\n",
        "display(Markdown(\"## ‚ú® Insights Gerados pelo Modelo Phi-3 Mini\"))\n",
        "display(Markdown(insights))\n",
        "print(\"#\"*50)"
      ],
      "metadata": {
        "id": "GeiFT64uTIvR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}